{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl4ciCkI+Wioavumgp0lQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saipklvs/LearnDL/blob/main/Visualize_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### These are the steps involved in this tutorial\n",
        "1. Read the data with appropriate transforms \n",
        "2. Set up Tensorboard\n",
        "3. Write to Tensorboard\n",
        "4. Inspect a model arcitecture using Tensorboard\n",
        "5. Use the tensorboard to create Interactive versions\n",
        "   a. A couple of ways to inspect our training data\n",
        "   b. How to tract our model's performance as it trains\n",
        "   c. How to assess our model's performance once it is trained"
      ],
      "metadata": {
        "id": "0gevR2DZRum9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "mhpviDstRuIY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mHOIuh5HV4SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272db46d-c290-478d-c73e-83ea6a880820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18588895.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 337939.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6062734.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 19540522.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(\n",
        "    \"./data\",\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform = transform\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.FashionMNIST(\n",
        "    \"./data\",\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "id": "CDPWAHyDTRDa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## dataloaders\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=2 \n",
        "    )\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, \n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "KpXu6Y3VTchu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constant for classes\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
      ],
      "metadata": {
        "id": "xKJ3T06pT9EE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper function to plot an image\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "  if one_channel:\n",
        "    img = img.mean(dim=0)\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  if one_channel:\n",
        "    plt.imshow(npimg, cmap=\"Greys\")\n",
        "  else:\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "metadata": {
        "id": "2chZfIF0UOcI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*4*4, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*4*4)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "net = Net()\n"
      ],
      "metadata": {
        "id": "kdadfzuUWfmm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "UGz_sEJRXXf5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorboard Setup"
      ],
      "metadata": {
        "id": "LQZh6DjsatR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "hYizotTRZ2zL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
      ],
      "metadata": {
        "id": "Qa6XhGUpa0Ve"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing an image to tensorboard\n"
      ],
      "metadata": {
        "id": "z_UM2GGKa6fX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "## Create the grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "## Show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "## Write to tensorboard\n",
        "writer.add_image(\"four_fashion_mnist_images\", img_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "5xMKc3zJa3Nt",
        "outputId": "bc3ecb98-d34a-4ebe-e3a1-e24b71672211"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAACxCAYAAADwMnaUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnKklEQVR4nO3de1DVdf4/8CeogIkcBQMkxLDcsLyVJpJOVzbX2sq0u61UzjQWVupumbup0xXT3WrNWzWVu1Ou5Uzq6qSOi6ldEBW1UhPdIkURvHIRFQg+vz++6/n5fp7T+XA44PkAz8eMM73O5fN5n/fnwrvzfp3XO8SyLAsiIiIiDhAa7AaIiIiInKOBiYiIiDiGBiYiIiLiGBqYiIiIiGNoYCIiIiKOoYGJiIiIOIYGJiIiIuIYGpiIiIiIY2hgIiIiIo6hgYmIiIg4RpMNTObOnYtLL70UERERSE1NxebNm5tqVyIiItJChDTFWjmffPIJxowZgwULFiA1NRVvvfUWlixZgvz8fMTGxvp8b11dHYqKitCxY0eEhIQ0dtNERESkCViWhYqKCiQkJCA0tOHfezTJwCQ1NRXXXnst5syZA+D/BhvdunXDU089heeff97new8ePIhu3bo1dpNERETkAigsLERiYmKD39+2EdsCAKiurkZeXh6mTJnifiw0NBTp6enIycnxeH1VVRWqqqrc8blx0iuvvIKIiIjGbp6IiIg0gbNnz+KFF15Ax44dA9pOow9Mjh07htraWsTFxRmPx8XFYc+ePR6vz8rKwosvvujxeEREBNq3b9/YzRMREZEmFGgaRtB/lTNlyhSUlZW5/xUWFga7SSIiIhIkjf6NSZcuXdCmTRuUlJQYj5eUlCA+Pt7j9eHh4QgPD2/sZoiIiEgz1OjfmISFhWHAgAHIzs52P1ZXV4fs7GykpaU19u5ERESkBWn0b0wAYNKkScjIyMDAgQMxaNAgvPXWW6isrMSjjz7aFLsTERGRFqJJBib3338/jh49imnTpqG4uBj9+/fH6tWrPRJiG+rJJ5/0+bzdL6AvRH0UTvR9+eWXjTgqKsqIIyMjjbi2ttaIebqrqKjIiI8fP27EM2bMMOLevXvbtNheY/frvHnzfD5vd5yledBxbh2aw3GeP3++Effs2dOIT548acScfsC1OU6dOuXz+fN/cQp43ufbtWtnxIcPHzbitm3NP9EjRoxAsNkd58bQJAMTABg/fjzGjx/fVJsXERGRFijov8oREREROUcDExEREXGMJpvKCaamyCEpLy834g8++MCIP/roIyMuLS01Ys6v+eabb4x42bJlRpySkmLEJ06cMOKHHnrIiHmuc9y4cUZcWVlpxN7me++44w4j5vlVrV0kIs3F2bNnPR5bunSpEXfo0MGIz5w5Y8Tbt2834osuusiIXS6XEXMOyS+//GLEfB/m/ffo0cOI9+/fb8ROyDG5EPSNiYiIiDiGBiYiIiLiGBqYiIiIiGO0yBwTf3FNEAD44x//aMQ8V1hRUWHE3bt3N+JevXoZMedr1NXVGfGPP/5oxDz3uH79ep/vHzx4sBF369bNZ3uXL18OtmbNGo/Hzjdr1iwjTk5O9vl6EZFg+fLLLz0e41w/rg/FdUhiY2ONmP8O8EKznTt3NuLi4mIj7tSpkxFHREQYcXV1tc/tf/7550Z82223oSXSNyYiIiLiGBqYiIiIiGNoYCIiIiKO0SJzTHhNF66/cfDgQSO+9957PbbRpUsXI+a5QZ575LVqOAeEf4/Ov1d///33fW6Pfx+fmprqs301NTVGfPr0aSPm398DnusycO2Wp59+2ojfeOMNI+Z1J+yOg4hIU5k9e7bHY3zf5fpQjHNOOFdw7969Rsz3Vc4V5PtwmzZtfO6f78nvvPOOESvHRERERKSJaWAiIiIijqGBiYiIiDiGBiYiIiLiGC0y+dUuyXLixIlGzAlOgGdSEictcXIpv54XkOLFn7iwztChQ31uPyEhwYg5MZXj2tpaI46KivK5f8BzAStOqOUibbwQ4Nq1a4040GRXTkzjpGX+DFzciGNOJBORloMXyPO2iB//iIDvCfwevufxPZLvs/y3xK6AG7+/Xbt2RszJtIWFhUZstyhgc6VvTERERMQxNDARERERx9DARERERByjVUy679ixw4gLCgqMmHMRAODkyZNGzAXXOH/CW57K+ThHhV/P+RI8d8gF2nhulOcy7Yql8fYBoGPHjkZ86NAhI+acE56P5ddfcsklHvvwR3R0tM/2cQG3sLAwI+aFGLdv327EkydP9tgnL0zIc8yBzuFyGzk3ic8L7mMu3MeLfDF+Pc9pe3usqqrKiHnhsiNHjhixXbE/kQvhwIEDRsz5GoDnuc34Psyv59y/fv36GXFZWZkR2+X28bXH922OOVeRc05SUlLQEugbExEREXEMDUxERETEMTQwEREREcdoFTkmr732mhFz/oi3HJOjR48asd1cH+O6I5xbwHODdr9n51yDw4cPGzHPhV5++eVGfOrUKSPmnBnAPg+Ff1PPbeRFs15//XWPfQTC25zx+Xbv3m3EX3/9tRHzAlxvvvmm7T44h8Nu0S0+jpyLxDkfjI8z57Rwvoe3nJHzcR5OdXW1x2u4Td5ecz6+fvr06WPE//znP32+X6QpFBUVGbG3+wVfD5xDxjkh/Lfh22+/NWK+J/Liq5xz0r17dyPm652vPW4Pfya7RQibK31jIiIiIo6hgYmIiIg4hgYmIiIi4hitIseEa4BwfQzOrQA8f2/OOR2cc3LFFVcYMed0cC4Ab59zULjuCees7Ny504i5dsR///tfI+bP2K1bNzDOHdi3b58R83wn59nw+y80ziXi/A7Ow+F1L7y9xtt6G+fj/Ay7OiV8HvAcNddR4ZohdvVwuD0ce1sjiee1+bhyjZyuXbsaMedLffPNNx77EGlqfG3weQt4Xi9cl6SkpMSIr7rqKiOOiYkxYv7bwtc754BwLSa+X9itL8Y5JvyZWwp9YyIiIiKOoYGJiIiIOIbfA5ONGzfijjvuQEJCAkJCQrBs2TLjecuyMG3aNHTt2hXt27dHenq6x5SAiIiIiDd+55hUVlaiX79+eOyxxzBy5EiP52fOnInZs2fjH//4B5KTkzF16lQMGzYMu3fv9jq/3RQWLFhgxD///LMR87yht1yD0tJSI+a2c44Jr9OQmJjo8/W8Pc4F4N/bc44Iz/NzbgTng3AND291WL777juf2+B98Hxpfn6+ES9atMiIH3roIY99NqbY2Fgj5rom3Kfe1gvi/CPGdQ+4zgnPGdvNIXMOC8+L83lod57w9u3WwQE8+43nrbmfeJ7ebt2n1sjuuDA+LtOnTzfiGTNmNE7DWjDO//B2rvP1ExcXZ8QHDx40Yl5n7ZprrvH5en/XsuLrna9X3h7nmPA9uKXwe2AyfPhwDB8+3OtzlmXhrbfewgsvvIC77roLwP8VW4qLi8OyZcvwwAMPBNZaERERadEaNcekoKAAxcXFSE9Pdz/mcrmQmpqKnJwcr++pqqpCeXm58U9ERERap0YdmBQXFwPw/HosLi7O/RzLysqCy+Vy//P2M1YRERFpHYJex2TKlCmYNGmSOy4vLw94cHLfffcZMedO7Nmzx4i5DgPgObefkpLi8/mkpCQj5hwOnrfnNRTs1mDhuUauGeItX+J8nOPC87GA54CS+4XzK3ibl112mREPGzbMZ5saG68jw33Kc85cQwSwnxPmuiK8T94H5/ZERkYaMa/vwXPafN7xMeK6C5yzwuedtxwabrPd+kAcc24R55y0RnY5JceOHTPiVatWGTFfe+PHjzfiOXPm+Ny+tzWZ7I4L58Vw7PTjyrWcvNX44OuDP5Pd9bVt2zYjvvjii42Y+4xzzPieyecJt4dzSjgHhdfSaika9Uw7dxPmg1lSUuJxgz4nPDwcUVFRxj8RERFpnRp1YJKcnIz4+HhkZ2e7HysvL0dubi7S0tIac1ciIiLSAvk9lXPq1Cmj3HlBQQF27NiB6OhoJCUlYcKECXjllVfQs2dP98+FExISMGLEiMZst4iIiLRAfg9Mtm7diptuuskdn8sPycjIwMKFC/Hcc8+hsrISjz/+OEpLSzF06FCsXr36gtY24Hn0efPmGTHP03300Uce2+C1ZoYMGWLEt99+uxH37t3biHmtHJ5b5LlBzl3gz8Bzoz169DBizlXg/Amef/VW9O6DDz4w4pkzZxoxf+v1yCOPGDF/xkD5WwuCX8/rYPD7veWTcD+e/wszwPO4v//++0bM5xb3CecOcL7Gr015nsPr2vBx5WlUnqO+7bbbPLbJdX527dplxJwXw/3Mn8FbjZzW7oUXXjDi1atXGzFfW3x/+Oyzz4zYLsfE7lqpz3saso1g4uuZ87+8PcbXK+MaP1yvin9FyteC3T2Iry3O47PL+/G2HlBL4PdfkhtvvNGjc84XEhKCl156CS+99FJADRMREZHWx9lp1iIiItKqaGAiIiIijhH0OibBwPOAGRkZtu/h2id2dUV47p/3yXODnTt3NmKem7TLUenZs6fP1/PPsLdu3QqWkJBgxJw/caH5O8fN+RdcE4BzH7z9NJ3rS7z33ntGnJuba8Q899+rVy8jfvXVV424f//+RsxzzBwfP37ciLluAh8jrgE0ZswYI77lllvAbr31ViMeOHCgEdutQcL1Iuzm7VuivLw8I77//vuNmI+r3bpOnIvEa7TYaUh+CNdCevTRR434008/9XubFxJf395y3viewPdZu/s212ri3EBed43THrimFq91w38X+Frj49pSc0z0jYmIiIg4hgYmIiIi4hgamIiIiIhjtMocE57387auhF19CZ7r43l1rmPC++DXc70Jzn/guVDOp2CHDx82Ys494DUhANjWmuHP4LS6B9xHPK/Pfeqtlgsf9xMnThgxrwvD9Wu4tgvPy/Nx5zlvrovAn2Hv3r1GzLkInBPDazotXboUjBfY5H7kfXIeDZ+73upH+OJvvRp/+Spv0NB9Pvvss0a8fv16I+Z8LT73OC+H8zv4WuQcFs5JW758uRFff/31Xlrt2yeffGLEfA/buXOnEfO5H2zcJ5wvAnjmnfC5wTkjfJw4J4Rju7V4+Lzga4/rU/G1xdvztvZVS6BvTERERMQxNDARERERx9DARERERByjVeaY8Hwyz9t5w3P9gwYNMmKel7er/cC5DDynzG3iuUjePs+vhoWFGTHnpPCaDIB93ovTckoYf0buc+5Tb+vScC0E3ibn7nTt2tWIH374YSPmPuJ6M3Zr2/Ax4Tnl3//+90bMc9gTJkwwYj6PAOC6664zYq6VwvPmfO5y7pG/OSbcR7w9zgPg42j3/vpc34zXjRo3bpwRcx9wvZjU1FQj3rZtmxHzcefaMbzuS05OjhFzXaW7777biL1d35wTwnktN9xwgxH36dPHiN99910jnj17tsc+gomvHW99wLk+fK7yNvi+yseRX8/3A65vxdc/36N++uknv9rL9/mWQt+YiIiIiGNoYCIiIiKOoYGJiIiIOEarzDFpCLvfv3MuAMcul8uIOXeB11jgGgI8l8jbt5srtcu3AOzXXWjqehOB4vbxZ+aaH5w7AXjWLeA1TRYsWGDEv/nNb4yYa3zwcebcAD5OjM8Drs3Aa6jwGkpr1qwx4h9++MFjH5yXsn//fp/btMvxCHStnIbkhPh6v7eaPytXrjTi6dOnGzHnfN15551G/OKLLxrxxo0bjXjWrFlGzNc/r7nC9XH4M/Tt29eIBw8ebMS8BgvnKgCeNXJ4H7t27TJiPvf5XDx06JDHPoKJz0POC/SGjwvn9vB9OTEx0YiHDh1qxHyuvfbaa0bM9aQ4J8VuDTbO/1KOiYiIiEgT08BEREREHEMDExEREXEMDUxERETEMZT8Cu+LfNkldnKiKCeGcTIqJ1VyQTZOruXtc1IUv58TOXn/nOjmbcE+pyW3+tseTjzjPuSiWN62x48VFRUZMSef/vjjj0bMiZ9lZWVGbLcoF7+fC74dOHDAiDmh0a5AHJ9nAHD8+HGfbeRzi5Nh7RLB/cXnNi9EyAutbd261Yg5wfjLL7/02AcnMfbv39+Ihw8fbsT9+vUzYk6C5sJbnOTIfciJ2FzIiz/DsmXLjPjmm2824quuuspnDADHjh0zYi7excUDud/5XPO3kN6F1r17d4/HeFFOu/smJ9BygnBWVpYRcx9ykTe+j/O1x/covp45Gbel0jcmIiIi4hgamIiIiIhjaGAiIiIijqEckwbiXASeZ+e5RM414Dlunlfv2LGjEXMhHS5uxHkB3B4uHNSQvBqn4zlxxgXXvBVY4zlezsngfXAOB/chzxFzTgnPafP++bywKwDFuUycZ+Mt/4PPLW6DHW6jvzkm/P6XX37ZiL///nsj5nOd+5ivHc4XATzzK3gfq1atMuLs7Gwj5kX14uLijJjPNW9F3s7HOWqc29CjRw8jPnjwoBFz/gf3AeC5iF9BQYER87ljdx54WxDSSbwt0nn06FEjtisWyDkifBx5H3bHnZ/3lut3Pv47wkXvWip9YyIiIiKOoYGJiIiIOIYGJiIiIuIYyjFBw3Ir7OpD1GchsfPxXCL/Hp7xHDTPB9vVy+DfzwPOq2PiL+5jzl2wm08G7PMj7PrVLubjHChuD38mPi+8LZDnbx0S3oddvpUd/gzTpk0z4tzcXCPm/I7du3cbMdee4RojgOfiaJyrw33AeTic61NSUuLz/Xx/4Nwizhnh9vBx4z7m65kXewM8F/bjNnA+EsfcJq7p4TSclwMA3377rc/3cL9yv/N5wH3EC2LyceccE96fXa4iL/7YUukbExEREXEMvwYmWVlZuPbaa9GxY0fExsZixIgRHst1nz17FpmZmYiJiUFkZCRGjRrl8X8TIiIiIt74NTDZsGEDMjMzsWnTJqxduxY1NTW49dZbUVlZ6X7NxIkTsWLFCixZsgQbNmxAUVERRo4c2egNFxERkZbHrxyT1atXG/HChQsRGxuLvLw8XH/99SgrK8P777+PRYsWuddy+PDDD9GrVy9s2rQJgwcPbryWBxnPFfJcI//Gn+cGeY47JibG5/54zppzB7iuCc+v2s2ZA80vp4RxzQF/cx284X7zNw+H54jtakPYredjlydj935vOS52OSOMt2E3L26HjxvnBg0ZMsRnzDjXiNelAYCff/7ZiPfv32/EXO+C1+fhNVc4/4KPA7eJjyPXVeH7QXR0tBFz/QuOXS4XGK/zxLVOeBt8T+PjwnVR3n33XY99Og1/BrvcIc7DsatLxNvjmF9vt2YaP8+5hS1VQDkm54qGnbto8vLyUFNTg/T0dPdrUlJSkJSU5JGwJiIiIsIa/Kucuro6TJgwAUOGDHGPnIuLixEWFuYxMo+Li/vVKoFVVVXGtw9cwVBERERajwZ/Y5KZmYmdO3di8eLFATUgKysLLpfL/Y+XCxcREZHWo0HfmIwfPx4rV67Exo0bjTVf4uPjUV1djdLSUuNbk5KSEq/rFgDAlClTMGnSJHdcXl7uyMEJr6vCc8g8z263xgrPXfKcMD/PuQ4818nzw7w2D3+LxdsHmn+OCef9cH0M1pDPy8e9PnVCfL2e1afWij/tsaufUZ/32K2Fw8/7m9vDuQ58rfG3rby/Dh06GDFfC95qP7SWehCB4Fwhu+PuNN6uf/5MdnWG+Prj9YTqs8/z8bVllyPG16u33MCWyK9vTCzLwvjx47F06VKsW7cOycnJxvMDBgxAu3btjAWv8vPzceDAAaSlpXndZnh4OKKioox/IiIi0jr59Y1JZmYmFi1ahOXLl6Njx47u/5NxuVxo3749XC4Xxo4di0mTJiE6OhpRUVF46qmnkJaW1qJ+kSMiIiJNw6+Byfz58wEAN954o/H4hx9+iEceeQQA8OabbyI0NBSjRo1CVVUVhg0bhnnz5jVKY0VERKRl82tgUp+544iICMydOxdz585tcKOciOdXee6P5yp53pvnze3ma3muk+fheS6Sp8B47pK337dvXzBuI8/VO13Pnj2NmGtV1Kfehr9r39jlmNjNadvNMdvlpPCcdUPY7dNu7RwW6HpAfN79Wn7aOXwtcq6Rt3WhuK4Ib4PPFb5+7PrM3/ozvH9/a8XUZ00muzbwcbY7150+7e4tV5H72W49Le4Tu3uiXb0ou3pU/DwfI/670lJprRwRERFxDA1MRERExDE0MBERERHHCHyCupXguT+7uiY8t8hzg1xnxO79PE/OOSd2NTw6d+5sxMeOHQPjbTS3HBNvNTrOx/P03nIn7HI6eBuB5ozY5SIwfr1d3he/3ludBT7uduu62J2rdp+hsXGeDcetZV5e7PH6P3yu8rVgV1eE8bnH2+PcH36e8fXLa/m0VPrGRERERBxDAxMRERFxDA1MRERExDGUY1JPPJfP8/A892e3pgLnfNjlNvD2eH+cD3LkyBEj5poD3vJHKisrjZjX73E6u9oynF/RpUsXj23wHLFdvQjepr/1KgKtY2KXD1KfHBZ+jV0NHN6niBN5u3/xucz5UXbXv925z9cXb4/fz39XOLarr9NS6RsTERERcQwNTERERMQxNDARERERx1COST1VVFQYMc/D81wlP885Ivx6/j0754R06tTJZ/s4Z4W3Z5fzAjgvd4DnU7lPWWFhoRGXlpYaMefl8Fo63vbBc8Z2x5nxHDXn9tjVNbHLQeE5bLscGG85K3br7fA8N5+bXGNn//79PrcnciF4O9f5Hsd1TexyPvzF1yNfSxzbXYtcP6ul0jcmIiIi4hgamIiIiIhjaGAiIiIijqEck3o6c+aMz+d5PpN/L89zlTyXaJdrwGvj8Fo7vPYNb49zHbzNZdqtA2GXT9HY/N3fnDlzjJjnj3l73tbK4X7i487H1W4O2W57/HqeA+dcIW6zXd0Du/YAnp/Jrs2cZ3PxxRcbcd++fY3466+/9tinSFOrz5pNdnWD+Hr0ttaUL3Zr4fD1aXd9e7tntUT6xkREREQcQwMTERERcQwNTERERMQxNDARERERx1Dyaz2dOnXKiO0Wa+IF8eySTzkx88SJE0YcGxtrxFzkihMUOekqOjraiLlgHOD5GZm/Bc8C5e/2b7rppiZqiQRCya8SDN4KRtotxsqJ3Xzf5oR6xsmp/fr1M2K7hUZZYxd8ay70jYmIiIg4hgYmIiIi4hgamIiIiIhjKMcE3uftOL+hoKDAiA8fPmzEvDgbzzXyIny8T84JcblcRsxzk3aL9PGifpyD4m2htR9//NGI+/fvb8Q831qfAkYiIsHgrWAkL+zJ90Ve6JPxPdLOtm3bjJhzTlhkZKQR2/2daKn0l0VEREQcQwMTERERcQwNTERERMQxlGOC+tXLGDZsmBGPGzfOiHk+8+effzZirmtityjg0aNHjZjrlvDv7fn5mJgYI77sssuMeOzYsR77vPnmm322STklItJcXHHFFR6PLVy40Ih37tzpcxvx8fFGfPnll/t8PS8CePLkSSP+/PPPjZhzXnh/nJOSlJTkc/8thf7SiIiIiGP4NTCZP38++vbti6ioKERFRSEtLQ2rVq1yP3/27FlkZmYiJiYGkZGRGDVqFEpKShq90SIiItIy+TUwSUxMxIwZM5CXl4etW7fi5ptvxl133YVdu3YBACZOnIgVK1ZgyZIl2LBhA4qKijBy5MgmabiIiIi0PCFWgMX3o6OjMWvWLNxzzz24+OKLsWjRItxzzz0AgD179qBXr17IycnB4MGD67W98vJyuFwu/PWvf7X9TbmIiIg4w5kzZ/CnP/0JZWVlHnmP/mhwjkltbS0WL16MyspKpKWlIS8vDzU1NUhPT3e/JiUlBUlJScjJyfnV7VRVVaG8vNz4JyIiIq2T3wOT77//HpGRkQgPD8e4ceOwdOlSXHnllSguLkZYWJhHhdO4uDgUFxf/6vaysrLgcrnc/7p16+b3hxAREZGWwe+ByRVXXIEdO3YgNzcXTzzxBDIyMrB79+4GN2DKlCkoKytz/yssLGzwtkRERKR587uOSVhYmPu33AMGDMCWLVvw97//Hffffz+qq6tRWlpqfGtSUlLi8dvs84WHhyM8PNz/louIiEiLE3Adk7q6OlRVVWHAgAFo164dsrOz3c/l5+fjwIEDSEtLC3Q3IiIi0gr49Y3JlClTMHz4cCQlJaGiogKLFi3C+vXrsWbNGrhcLowdOxaTJk1CdHQ0oqKi8NRTTyEtLa3ev8gRERGR1s2vgcmRI0cwZswYHD58GC6XC3379sWaNWvw29/+FgDw5ptvIjQ0FKNGjUJVVRWGDRuGefPm+dWgc79ePnv2rF/vExERkeA593c7wCokgdcxaWwHDx7UL3NERESaqcLCQiQmJjb4/Y4bmNTV1aGoqAiWZSEpKQmFhYUBFWpp7crLy9GtWzf1YwDUh4FTHzYO9WPg1IeB+7U+tCwLFRUVSEhICGjRV8etLhwaGorExER3obVz6/JIYNSPgVMfBk592DjUj4FTHwbOWx+6XK6At6vVhUVERMQxNDARERERx3DswCQ8PBzTp09X8bUAqR8Dpz4MnPqwcagfA6c+DFxT96Hjkl9FRESk9XLsNyYiIiLS+mhgIiIiIo6hgYmIiIg4hgYmIiIi4hiOHZjMnTsXl156KSIiIpCamorNmzcHu0mOlZWVhWuvvRYdO3ZEbGwsRowYgfz8fOM1Z8+eRWZmJmJiYhAZGYlRo0ahpKQkSC12vhkzZiAkJAQTJkxwP6Y+rJ9Dhw7h4YcfRkxMDNq3b48+ffpg69at7ucty8K0adPQtWtXtG/fHunp6di3b18QW+wstbW1mDp1KpKTk9G+fXtcdtllePnll431R9SHpo0bN+KOO+5AQkICQkJCsGzZMuP5+vTXiRMnMHr0aERFRaFTp04YO3YsTp06dQE/RfD56seamhpMnjwZffr0QYcOHZCQkIAxY8agqKjI2EZj9KMjByaffPIJJk2ahOnTp2Pbtm3o168fhg0bhiNHjgS7aY60YcMGZGZmYtOmTVi7di1qampw6623orKy0v2aiRMnYsWKFViyZAk2bNiAoqIijBw5Moitdq4tW7bgnXfeQd++fY3H1Yf2Tp48iSFDhqBdu3ZYtWoVdu/ejb/97W/o3Lmz+zUzZ87E7NmzsWDBAuTm5qJDhw4YNmyYFu78n9dffx3z58/HnDlz8MMPP+D111/HzJkz8fbbb7tfoz40VVZWol+/fpg7d67X5+vTX6NHj8auXbuwdu1arFy5Ehs3bsTjjz9+oT6CI/jqx9OnT2Pbtm2YOnUqtm3bhs8++wz5+fm48847jdc1Sj9aDjRo0CArMzPTHdfW1loJCQlWVlZWEFvVfBw5csQCYG3YsMGyLMsqLS212rVrZy1ZssT9mh9++MECYOXk5ASrmY5UUVFh9ezZ01q7dq11ww03WM8884xlWerD+po8ebI1dOjQX32+rq7Oio+Pt2bNmuV+rLS01AoPD7f+9a9/XYgmOt7tt99uPfbYY8ZjI0eOtEaPHm1ZlvrQDgBr6dKl7rg+/bV7924LgLVlyxb3a1atWmWFhIRYhw4dumBtdxLuR282b95sAbD2799vWVbj9aPjvjGprq5GXl4e0tPT3Y+FhoYiPT0dOTk5QWxZ81FWVgYAiI6OBgDk5eWhpqbG6NOUlBQkJSWpT0lmZiZuv/12o68A9WF9/fvf/8bAgQNx7733IjY2FldffTXee+899/MFBQUoLi42+tHlciE1NVX9+D/XXXcdsrOzsXfvXgDAt99+i6+++grDhw8HoD70V336KycnB506dcLAgQPdr0lPT0doaChyc3MveJubi7KyMoSEhKBTp04AGq8fHbeI37Fjx1BbW4u4uDjj8bi4OOzZsydIrWo+6urqMGHCBAwZMgS9e/cGABQXFyMsLMx98pwTFxeH4uLiILTSmRYvXoxt27Zhy5YtHs+pD+vnp59+wvz58zFp0iT8+c9/xpYtW/D0008jLCwMGRkZ7r7ydn2rH//P888/j/LycqSkpKBNmzaora3Fq6++itGjRwOA+tBP9emv4uJixMbGGs+3bdsW0dHR6tNfcfbsWUyePBkPPvigeyG/xupHxw1MJDCZmZnYuXMnvvrqq2A3pVkpLCzEM888g7Vr1yIiIiLYzWm26urqMHDgQLz22msAgKuvvho7d+7EggULkJGREeTWNQ+ffvopPv74YyxatAhXXXUVduzYgQkTJiAhIUF9KI5QU1OD++67D5ZlYf78+Y2+fcdN5XTp0gVt2rTx+LVDSUkJ4uPjg9Sq5mH8+PFYuXIlvvjiCyQmJrofj4+PR3V1NUpLS43Xq0//v7y8PBw5cgTXXHMN2rZti7Zt22LDhg2YPXs22rZti7i4OPVhPXTt2hVXXnml8VivXr1w4MABAHD3la7vX/fss8/i+eefxwMPPIA+ffrgD3/4AyZOnIisrCwA6kN/1ae/4uPjPX5c8csvv+DEiRPqU3JuULJ//36sXbvW/W0J0Hj96LiBSVhYGAYMGIDs7Gz3Y3V1dcjOzkZaWloQW+ZclmVh/PjxWLp0KdatW4fk5GTj+QEDBqBdu3ZGn+bn5+PAgQPq0/+55ZZb8P3332PHjh3ufwMHDsTo0aPd/60+tDdkyBCPn6rv3bsX3bt3BwAkJycjPj7e6Mfy8nLk5uaqH//n9OnTCA01b81t2rRBXV0dAPWhv+rTX2lpaSgtLUVeXp77NevWrUNdXR1SU1MveJud6tygZN++ffjPf/6DmJgY4/lG68cGJOs2ucWLF1vh4eHWwoULrd27d1uPP/641alTJ6u4uDjYTXOkJ554wnK5XNb69eutw4cPu/+dPn3a/Zpx48ZZSUlJ1rp166ytW7daaWlpVlpaWhBb7Xzn/yrHstSH9bF582arbdu21quvvmrt27fP+vjjj62LLrrI+uijj9yvmTFjhtWpUydr+fLl1nfffWfdddddVnJysnXmzJkgttw5MjIyrEsuucRauXKlVVBQYH322WdWly5drOeee879GvWhqaKiwtq+fbu1fft2C4D1xhtvWNu3b3f/WqQ+/fW73/3Ouvrqq63c3Fzrq6++snr27Gk9+OCDwfpIQeGrH6urq60777zTSkxMtHbs2GH8ramqqnJvozH60ZEDE8uyrLfffttKSkqywsLCrEGDBlmbNm0KdpMcC4DXfx9++KH7NWfOnLGefPJJq3PnztZFF11k3X333dbhw4eD1+hmgAcm6sP6WbFihdW7d28rPDzcSklJsd59913j+bq6Omvq1KlWXFycFR4ebt1yyy1Wfn5+kFrrPOXl5dYzzzxjJSUlWREREVaPHj2sv/zlL8bNX31o+uKLL7zeAzMyMizLql9/HT9+3HrwwQetyMhIKyoqynr00UetioqKIHya4PHVjwUFBb/6t+aLL75wb6Mx+jHEss4rJygiIiISRI7LMREREZHWSwMTERERcQwNTERERMQxNDARERERx9DARERERBxDAxMRERFxDA1MRERExDE0MBERERHH0MBEREREHEMDExEREXEMDUxERETEMTQwEREREcf4fydgFRrkwnMRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the model using TensorBoard"
      ],
      "metadata": {
        "id": "bqW5SvW8b0Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer.add_graph(net, images)\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "VxP9Z2Iebci8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a \"Projector\" to Tensorboard"
      ],
      "metadata": {
        "id": "KsInNIGPcOfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_n_randoms(data, labels, n=100):\n",
        "    \"\"\"\n",
        "    Selects n random datapoints and their corresponding labels from a dataset\n",
        "    \"\"\"\n",
        "    assert len(data) == len(labels)\n",
        "    perm = torch.randperm(len(data))\n",
        "    return data[perm][:n], labels[perm][:n]\n",
        "\n",
        "## Select the random images and their target indices\n",
        "images, labels = select_n_randoms(trainset.data, trainset.targets)\n",
        "\n",
        "## Get the class labels for each image\n",
        "class_labels = [classes[lab] for lab in labels]\n",
        "\n",
        "## Log Embeddings\n",
        "features = images.view(-1, 28*28)\n",
        "\n",
        "writer.add_embedding(features,\n",
        "                    metadata=class_labels,\n",
        "                    label_img=images.unsqueeze(1))\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "BvewtVoLbkgx"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking model training with TensorBoard\n"
      ],
      "metadata": {
        "id": "K2IcHddpebGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Helper function\n",
        "def images_to_probs(net, images):\n",
        "  output = net(images)\n",
        "  _, preds_tensor = torch.max(output, 1)\n",
        "  preds = np.squeeze(preds_tensor.numpy())\n",
        "  return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
      ],
      "metadata": {
        "id": "2p_KaP40eTAd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classes_preds(net, images, labels):\n",
        "  print(labels)\n",
        "  preds, probs = images_to_probs(net, images)\n",
        "  print(probs)\n",
        "  print(preds)\n",
        "  fig = plt.figure(figsize=(12, 48))\n",
        "  for idx in np.arange(4):\n",
        "    ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "    matplotlib_imshow(images[idx], one_channel=True)\n",
        "    ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "            classes[preds[idx]],\n",
        "            probs[idx] * 100.0,\n",
        "            classes[labels[idx]]),\n",
        "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig"
      ],
      "metadata": {
        "id": "TVJPN2HTgzyz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "running_loss = 0.0\n",
        "for epoch in range(1):\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if i % 1000 == 999:\n",
        "      writer.add_scalar(\n",
        "          \"training_loss\", \n",
        "          running_loss / 1000, \n",
        "          epoch * len(trainloader) + i)\n",
        "      writer.add_figure(\n",
        "          'predictions vs. actuals', \n",
        "          plot_classes_preds(net, inputs, labels),\n",
        "          global_step=epoch * len(trainloader) + i\n",
        "      )\n",
        "      running_loss = 0.0\n",
        "print(\"Finised_Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fRX7jgZhanv",
        "outputId": "3520ef08-855a-4a63-feaf-f4d5f27a9e66"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 8, 9])\n",
            "[0.5558412075042725, 0.5783829092979431, 0.9575377106666565, 0.9368308186531067]\n",
            "[3 6 8 9]\n",
            "tensor([8, 5, 4, 7])\n",
            "[0.48873376846313477, 0.7463531494140625, 0.5311130285263062, 0.991238534450531]\n",
            "[4 5 4 7]\n",
            "tensor([5, 3, 2, 6])\n",
            "[0.9958279728889465, 0.9305310249328613, 0.757926344871521, 0.5381201505661011]\n",
            "[5 3 2 6]\n",
            "tensor([7, 3, 8, 1])\n",
            "[0.9970439076423645, 0.8394990563392639, 0.9975908994674683, 0.9970968961715698]\n",
            "[7 3 8 1]\n",
            "tensor([7, 6, 3, 6])\n",
            "[0.6998523473739624, 0.9616605043411255, 0.4514884352684021, 0.7757743000984192]\n",
            "[7 6 4 6]\n",
            "tensor([2, 5, 4, 3])\n",
            "[0.9473837018013, 0.9810464978218079, 0.9415860772132874, 0.8133135437965393]\n",
            "[2 5 4 3]\n",
            "tensor([6, 3, 5, 6])\n",
            "[0.7530270218849182, 0.5013067126274109, 0.999750554561615, 0.6964061856269836]\n",
            "[0 4 5 0]\n",
            "tensor([7, 6, 3, 6])\n",
            "[0.9211679697036743, 0.48572874069213867, 0.99116450548172, 0.7632116675376892]\n",
            "[7 2 3 6]\n",
            "tensor([2, 0, 7, 7])\n",
            "[0.8252214789390564, 0.8573103547096252, 0.9946534633636475, 0.9993969202041626]\n",
            "[4 0 7 7]\n",
            "tensor([6, 5, 3, 2])\n",
            "[0.26267898082733154, 0.9902288913726807, 0.7641841173171997, 0.911293625831604]\n",
            "[4 5 3 2]\n",
            "tensor([6, 5, 0, 4])\n",
            "[0.8945644497871399, 0.9994753003120422, 0.9714405536651611, 0.9134905338287354]\n",
            "[0 5 0 4]\n",
            "tensor([1, 0, 7, 9])\n",
            "[0.9499731659889221, 0.5342081189155579, 0.905743420124054, 0.9802425503730774]\n",
            "[1 6 7 9]\n",
            "tensor([0, 4, 3, 7])\n",
            "[0.5270301103591919, 0.8872848153114319, 0.8345382809638977, 0.996859073638916]\n",
            "[0 4 3 7]\n",
            "tensor([4, 8, 3, 7])\n",
            "[0.9253418445587158, 0.9992515444755554, 0.9976522326469421, 0.9958321452140808]\n",
            "[4 8 3 7]\n",
            "tensor([1, 3, 9, 6])\n",
            "[0.9999099969863892, 0.8609392642974854, 0.7025766968727112, 0.6732302308082581]\n",
            "[1 3 7 0]\n",
            "Finised_Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assessing trained models with TensorBoard"
      ],
      "metadata": {
        "id": "DOYHM1a5jbxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
        "# 2. gets the preds in a test_size Tensor\n",
        "class_probs = []\n",
        "class_label = []\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    output = net(images)\n",
        "    class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
        "    class_probs.append(class_probs_batch)\n",
        "    class_label.append(labels)\n",
        "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
        "test_label = torch.cat(class_label)\n",
        "\n",
        "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
        "    '''\n",
        "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
        "    precision-recall curve\n",
        "    '''\n",
        "    tensorboard_truth = test_label == class_index\n",
        "    tensorboard_probs = test_probs[:, class_index]\n",
        "\n",
        "    writer.add_pr_curve(classes[class_index],\n",
        "                        tensorboard_truth,\n",
        "                        tensorboard_probs,\n",
        "                        global_step=global_step)\n",
        "    writer.close()\n",
        "\n",
        "# plot all the pr curves\n",
        "for i in range(len(classes)):\n",
        "    add_pr_curve_tensorboard(i, test_probs, test_label)\n"
      ],
      "metadata": {
        "id": "yQIS6a6viTwH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGQnyiNikYRp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}